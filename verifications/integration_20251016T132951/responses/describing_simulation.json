{"content":"# Describing Simulation\n\n> Synthesized from `instruction_documents/Describing_Simulation_0_codifying_simulations.md`,\n> `instruction_documents/Describing_Simulation_0_theory.md`, and the staged\n> checkpoints under Phase 2 of the schedule of work.\n\nThe Sim-Eval project defines an agent-oriented methodology for turning natural\nlanguage hypotheticals into executable simulations. This document summarises the\ncore architecture, runtime players, and operational surface that together enable\ninteractive simulation and evaluation.\n\n## 1. Problem Framing\n\n- **Comparative temporality:** Prompts explore how an environment evolves across\n  discrete ticks, so the engine models state at each step.\n- **Endogeneity:** Systems that drive change operate within the environment; the\n  simulation does not rely on external omniscient forces.\n- **Relational conditionality:** Entities interact through components and\n  systems, allowing cause-and-effect reasoning to be captured explicitly.\n\nThe methodology translates prompts into intent-complete specifications, then\ncodifies those specs using a staged workflow (skeletons → test intents → tests →\nimplementation → validation).\n\n## 2. Core Primitives\n\n### 2.1 Entity\nRepresents an addressable unit in the world. An entity is an ID with an\nassociated set of components. Entities are created and managed through the\n`EntityManager`, which ensures that component attachments stay consistent.\n\n### 2.2 ComponentType & ComponentManager\nComponents hold structured data (state, configuration, signals). `ComponentType`\nderives schemas and default values, while `ComponentManager` attaches component\ninstances to entities and provides query/update operations.\n\n### 2.3 System & SystemManager\nSystems implement behaviour that runs on each tick. They receive access to the\nentity/component infrastructure and may emit outbound frames. `SystemManager`\nregisters systems, defines execution order, and invokes lifecycle hooks\n(`onInit`, `update`, `onDestroy`).\n\n### 2.4 Time\nThe `TimeComponent` captures tick metadata and the `TimeSystem` increments the\nglobal tick, ensuring deterministic progression of the simulation loop.\n\n## 3. Messaging Model\n\n- **Inbound bus:** Receives control operations (`simulation.start`,\n  `evaluation.frame`, etc.). Handlers transform these operations into player\n  actions, allowing HTTP routes, CLI tools, or other transports to share the\n  same inbound vocabulary.\n- **Outbound bus:** Broadcasts acknowledgements and frames. Frame messages feed\n  the SSE endpoints; acknowledgement messages confirm whether a requested\n  mutation succeeded.\n- **Acknowledgements:** Every control message yields an acknowledgement object\n  containing a `messageId`, `status`, and optional `detail` field. Routes map\n  `status: success` to HTTP 200 and `status: error` to HTTP 500.\n\nThis publish/subscribe pattern decouples transport code from player logic and\nensures alignment with future automation channels.\n\n## 4. Runtime Players\n\n### 4.1 Simulation Player\n\n- Hosts the primary environment.\n- Registers default systems (including `TimeSystem`) and components.\n- Consumes inbound lifecycle messages (`simulation.start`, `pause`, `stop`) and\n  dynamic content operations (`simulation.system.inject`, etc.).\n- Publishes frames representing the full environment snapshot each tick.\n\n### 4.2 Evaluation Player\n\n- Provides a sandbox for analysing recorded frames.\n- Receives injected systems/components tailored to evaluation (e.g., detectors,\n  metrics aggregators).\n- Accepts frames through `evaluation.frame` messages; frames can originate from\n  the simulation loop or data stores.\n- Streams processed frames and acknowledgements back to observers.\n\n### 4.3 Frame Bridging\n\n`main.ts` wires a bridge that forwards simulation frames to the evaluation\nplayer by emitting `evaluation.frame` messages. This default bridge can be\naugmented or replaced by bespoke evaluation workflows.\n\n## 5. Server Composition\n\nThe HTTP server (`Server.ts`) wraps Node’s `http` module. It:\n\n1. Builds Simulation and Evaluation players, each with their own inbound and\n   outbound buses.\n2. Registers route modules that expose the API surface.\n3. Manages lifecycle hooks (`start`, `stop`, `dispose`) so tests and tools can\n   spin the service up and down deterministically.\n\n### 5.1 Router\n\nThe router supports method/path matching, parameter extraction, JSON body\nparsing, and default JSON responses. It keeps route definitions immutable, which\nenables tests to assert the registered surface.\n\n### 5.2 Information Routes\n\n- `/` emits a discoverability payload describing the major route families.\n- `/information/Describing_Simulation.md` and `/information/api.md` serve the\n  markdown files found in `src/routes/information/`.\n\n### 5.3 Simulation & Evaluation Routes\n\n- Lifecycle commands publish inbound messages and await acknowledgements.\n- System/component routes manipulate registries on the respective players.\n- Streaming routes (`/simulation/stream`, `/evaluation/stream`) convert outbound\n  frames into Server-Sent Events with keep-alive heartbeats.\n\n### 5.4 Codebase Routes\n\nThese routes let operators inspect and extend the runtime codebase:\n\n- `GET /codebase/tree` recursively enumerates the repository.\n- `GET /codebase/file` returns file contents after validating relative paths.\n- `POST /codebase/plugin` installs plugins into `plugins/`, creating directories\n  on demand while preventing directory traversal.\n\n### 5.5 System Routes\n\n- `GET /health` returns route metadata plus a timestamp.\n- `GET /status` reports whether each player is running and the current tick.\n\n## 6. Plugin Layout\n\nThe runtime separates built-in simulation logic from user-defined plugins:\n\n```\nplugins/\n  simulation/\n    components/\n    systems/\n    operations/\n  evaluation/\n    components/\n    systems/\n    operations/\n```\n\nPlugins uploaded through the API should adhere to this structure. The evaluation\nplugins can differ from simulation plugins, enabling tailored analytics.\n\n## 7. Development Workflow\n\n1. **Skeletons:** Create module shells that align with the instruction set.\n2. **Test intents:** Document behavioural expectations using comment-only tests.\n3. **Tests:** Convert intents into executable Vitest suites.\n4. **Implementation:** Fill in the skeletons to satisfy tests, respecting the\n   messaging contracts above.\n5. **Validation:** Run `npm test` (and eventually the integration harness) on a\n   clean build.\n6. **Integration:** Execute `tools/run_integration.sh` to simulate first-time\n   usage, including plugin uploads and SSE verification.\n\nThis discipline prevents large leaps of logic and ensures the spec remains a\nliving document throughout implementation.\n\n## 8. Integration Stages\n\nThe integration script performs six stages:\n\n1. Build the TypeScript bundle and start the service.\n2. Query informational endpoints to confirm documentation coverage.\n3. Capture `/status` before the simulation starts (should report idle players).\n4. Upload exemplar plugins to the runtime directory.\n5. Start the simulation and confirm acknowledgement success.\n6. Inject an evaluation frame and confirm that the SSE stream emits data.\n\nResulting artifacts are stored under `verifications/` with timestamped\ndirectories, providing evidence for manual and automated auditors.\n\n## 9. Glossary\n\n- **Frame:** A serialized snapshot of entities, components, and derived state at\n  a given tick.\n- **Acknowledgement:** Message confirming success or failure of an inbound\n  operation.\n- **Inbound Handler Registry:** Registry that maps inbound message types to\n  handlers on a player.\n- **Player:** A runtime orchestrator (`SimulationPlayer`, `EvaluationPlayer`)\n  that processes inbound messages and produces outbound frames.\n\n## 10. Further Reading\n\n- `instruction_documents/Describing_Simulation_0_theory.md` — foundational\n  concepts driving the simulation methodology.\n- `instruction_documents/Describing_Simulation_0_codifying_simulations.md` —\n  step-by-step instructions for building the sim-eval server.\n- `instruction_documents/Describing_Simulation_0_api_map.md` — enumerated API\n  reference mirrored by `/information/api.md`.\n\nMaintaining parity between these instructions and the runtime artifacts is a\nPhase 4 alignment goal. Any deviations should be recorded in `memory/exceptions/`.\n"}